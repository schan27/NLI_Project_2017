{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from os.path import join, exists\n",
    "import pandas as pd\n",
    "\n",
    "# input\n",
    "train_docs = join('data', 'essays', 'train', 'tokenized')\n",
    "dev_docs = join('data', 'essays', 'dev', 'tokenized')\n",
    "train_labels = join('data', 'labels', 'train', 'labels.train.csv')\n",
    "dev_labels = join('data', 'labels', 'dev', 'labels.dev.csv')\n",
    "\n",
    "# output\n",
    "train_csv_name = 'train_features.csv'\n",
    "dev_csv_name = 'dev_features.csv'\n",
    "\n",
    "def _load_docs(dir_name):\n",
    "    print(dir_name)\n",
    "    \n",
    "    docs = []\n",
    "    ids = []\n",
    "    for fn in tqdm(listdir(dir_name)):\n",
    "        if '.txt' in fn:\n",
    "            ids.append(fn.split('.')[0])\n",
    "            with open(join(dir_name, fn)) as f:\n",
    "                docs.append(f.read())\n",
    "        \n",
    "    docs = pd.Series(docs, ids)\n",
    "    docs.sort_index(inplace=True)\n",
    "    return docs\n",
    "    \n",
    "    \n",
    "def load_docs(orig_dir, out_name):\n",
    "    out_path = join(orig_dir, out_name)\n",
    "    if exists(out_path):\n",
    "        return pd.read_csv(out_path, encoding='utf-8', low_memory=False, index_col=0)\n",
    "    else:\n",
    "        docs = _load_docs(orig_dir)\n",
    "        data = pd.DataFrame({ORIG: docs})\n",
    "        data.to_csv(out_path, encoding='utf-8')\n",
    "        return data\n",
    "    \n",
    "    \n",
    "train_data = load_docs(train_docs, train_csv_name)['original']\n",
    "dev_data = load_docs(dev_docs, dev_csv_name)['original']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import array, concatenate\n",
    "\n",
    "def load_labels(csv_name):\n",
    "    df = pd.read_csv(csv_name)\n",
    "    df.index = df['test_taker_id']\n",
    "    labels = df['L1']\n",
    "    labels.sort_index(inplace=True)\n",
    "    return array(labels, dtype=pd.Series)\n",
    "\n",
    "\n",
    "y_train = load_labels(train_labels)\n",
    "y_dev = load_labels(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__-C%3A-Users-sophia-Desktop-school-CSC 485E-project-NLI_Project_2017-nli-shared-task-2017-__ipython-input__.get_X...\n",
      "get_X(1        Knowledge helps an inidvidual in making his ca...\n",
      "3        Traveling around the world and discovering new...\n",
      "5        In my opinion the best way to travel is in a g...\n",
      "6        I disagree that in twenty years there will be ...\n",
      "7        I strongly agree that successful people try ne...\n",
      "8        On The Premium Art of Risk Taking\\n\\nSuccess i...\n",
      "9        IDEAS AND FACTS\\n\\nI desagree with the stateme...\n",
      "10       I agree with the statement .\\nKnowing facts is...\n",
      "11       The statement `` in twenty years there will be...\n",
      "13       Today , most young people are very busy about ...\n",
      "14       It is an increasingly busy life that we all , ...\n",
      "15       In my opinion , I agree with that it is mo..., \n",
      "['word', 'character'], 'train')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack, csr_matrix, issparse\n",
    "from sklearn.externals.joblib import Memory\n",
    "mem = Memory('./mycache')\n",
    "\n",
    "tokenize = lambda x: x.split()\n",
    "word_vect = TfidfVectorizer(tokenizer=tokenize, stop_words=None, ngram_range=(1, 3), binary=True)\n",
    "char_vect = TfidfVectorizer(analyzer='char_wb', ngram_range=(4, 5), binary=True)\n",
    "\n",
    "WORD = 'word'\n",
    "CHAR = 'character'\n",
    "\n",
    "@mem.cache\n",
    "def get_X(data, features, mode):\n",
    "    Xs = []\n",
    "    for feat in features:\n",
    "        if feat == WORD:\n",
    "            vect = word_vect\n",
    "        elif feat == CHAR:\n",
    "            vect = char_vect\n",
    "        \n",
    "        if mode == 'train':\n",
    "            X = vect.fit_transform(data)\n",
    "        else:\n",
    "            X = vect.transform(data)\n",
    "        \n",
    "        if not issparse(X):\n",
    "            X = csr_matrix(X)\n",
    "            \n",
    "        Xs.append(X)\n",
    "    \n",
    "    return hstack(tuple(Xs))\n",
    "\n",
    "\n",
    "X_train = get_X(train_data, [WORD, CHAR], 'train')\n",
    "X_dev = get_X(dev_data, [WORD, CHAR], 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# layer 1\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "start = time.time()\n",
    "svm = LinearSVC()\n",
    "svm_bagging = BaggingClassifier(base_estimator=svm, n_estimators=10, bootstrap_features=True)\n",
    "svm_bagging.fit(X_train, y_train)\n",
    "time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle the svm bagging classifier\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(svm_bagging, 'svm_bagging.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# still layer 1 \n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "start = time.time()\n",
    "nb = BernoulliNB()\n",
    "nb_bagging = BaggingClassifier(base_estimator=nb, n_estimators=10, bootstrap_features=True)\n",
    "nb_bagging.fit(X_train, y_train)\n",
    "time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode(num):\n",
    "    arr = np.zeros(11)\n",
    "    arr[num] = 1\n",
    "    return arr\n",
    "\n",
    "\n",
    "def get_X_meta(X, mode='train'):\n",
    "    meta = []\n",
    "    for clf in tqdm(svm_bagging.estimators_ + nb_bagging.estimators_):\n",
    "        predictions = clf.predict(X)\n",
    "        meta.append(predictions)\n",
    "        \n",
    "    meta = array(meta).transpose()\n",
    "    X_meta = []\n",
    "    \n",
    "    for row in meta:\n",
    "        if len(set(row)) != 1:\n",
    "            print('different predictions!')\n",
    "            \n",
    "        row = [encode(x) for x in row]\n",
    "        X_meta.append(np.concatenate(row))\n",
    "        \n",
    "    return X_meta\n",
    "    \n",
    "    \n",
    "X_train_meta = get_X_meta(X_train, mode='train')\n",
    "X_dev_meta = get_X_meta(X_dev, mode='dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1100x55 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5500 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layer 2\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "svm = LinearSVC()\n",
    "ridge = Ridge()\n",
    "\n",
    "probs = []\n",
    "\n",
    "# for ensemble fusion, use mean probability rule \n",
    "for clf in [lda, svm, ridge]:\n",
    "    clf.fit(X_train_meta, y_train)\n",
    "    prediction = clf.predict_proba(X_dev_meta)\n",
    "    probs.append(prediction)\n",
    "    \n",
    "    \n",
    "# Experiment with different voting schemes"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
